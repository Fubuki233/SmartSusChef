{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmartSus Chef: The Universal Predictive Engine\n",
    "**Version:** 2.0 (Production Ready) | **Context:** Singapore & China | **Architecture:** Champion-Challenger\n",
    "\n",
    "## üìñ How to read this Notebook\n",
    "This engine is designed to predict food demand for F&B operators. It follows a strict pipeline:\n",
    "1.  **Context Detection:** Where is the restaurant? (SG or CN?) -> Load correct Holidays/Weather.\n",
    "2.  **Data Ingestion:** Fetch sales history from MySQL (or CSV fallback).\n",
    "3.  **Sanitation:** Fix \"Lazy Employee\" data (missing days) using interpolation.\n",
    "4.  **Evaluation (The Battle):** Hide the last 30 days, train on the past, and see which model guesses the hidden days better.\n",
    "5.  **Production Training:** Retrain BOTH models on 100% of data so they are ready for tomorrow.\n",
    "6.  **Prediction:** Serve the forecast via API logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 0: IMPORTS & SETUP ---\n",
    "# We import standard data libraries (pandas/numpy) and our ML models (Prophet/CatBoost).\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import pickle\n",
    "import os\n",
    "import shap\n",
    "from sqlalchemy import create_engine\n",
    "from prophet import Prophet\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') # Keep the output clean\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìç Step 1: Context Awareness (Location Logic)\n",
    "The model needs to know if it is in **Singapore** (Tropical, Hari Raya) or **China** (4-Seasons, Lunar New Year).\n",
    "We determine this automatically using the restaurant's GPS coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_code(lat, lon):\n",
    "    \"\"\"\n",
    "    Simple Bounding Box Logic.\n",
    "    If the coordinates are inside Singapore box, return 'SG'. Else, default to 'CN'.\n",
    "    \"\"\"\n",
    "    # Singapore is roughly Lat 1.1-1.5, Lon 103.5-104.1\n",
    "    if (1.1 <= lat <= 1.5) and (103.5 <= lon <= 104.1):\n",
    "        return 'SG'\n",
    "    return 'CN'\n",
    "\n",
    "def add_local_context(df, lat, lon):\n",
    "    \"\"\"\n",
    "    Enriches the sales data with local context features (Holidays + Weather).\n",
    "    \"\"\"\n",
    "    country_code = get_country_code(lat, lon)\n",
    "    print(f\"üåç Detected Location: {country_code} (Lat: {lat}, Lon: {lon})\")\n",
    "    \n",
    "    # 1. Standard Time Features\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    \n",
    "    # 2. HOLIDAY LOGIC\n",
    "    # We fetch the official public holidays for the specific country.\n",
    "    if country_code == 'SG':\n",
    "        local_holidays = holidays.SG(years=[2024, 2025, 2026])\n",
    "    else:\n",
    "        local_holidays = holidays.CN(years=[2024, 2025, 2026])\n",
    "        \n",
    "    # Create a binary feature: 1 = Holiday, 0 = Normal Day\n",
    "    df['is_public_holiday'] = df['date'].apply(lambda x: 1 if x in local_holidays else 0)\n",
    "    \n",
    "    # 3. WEATHER SIMULATION (Placeholder for API)\n",
    "    # (In Phase 2, you will replace this with a real API call to OpenWeatherMap)\n",
    "    def estimate_rain(row):\n",
    "        m = row['month']\n",
    "        if country_code == 'SG':\n",
    "            # SG: Wet season is Nov-Jan\n",
    "            return np.random.uniform(15, 60) if m in [11, 12, 1] else np.random.uniform(5, 30)\n",
    "        else:\n",
    "            # CN: Wet season is Summer (Jun-Aug)\n",
    "            return np.random.uniform(20, 80) if m in [6, 7, 8] else np.random.uniform(5, 25)\n",
    "        \n",
    "    df['rain_lunch_vol'] = df.apply(estimate_rain, axis=1)\n",
    "    return df, country_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 2: Data Ingestion & Sanitation\n",
    "Here we connect to the database. Crucially, we apply the **\"Anti-Lazy Employee\"** fix.\n",
    "If the database has holes (missing days), the model will think sales were 0. We must fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_training_data():\n",
    "    \"\"\"\n",
    "    Tries to connect to MySQL. If it fails (e.g., you are testing locally without DB),\n",
    "    it falls back to 'food_sales.csv' so you can still run the code.\n",
    "    \"\"\"\n",
    "    # DB CONFIG (Update this with your real credentials)\n",
    "    DB_URL = \"mysql+pymysql://root:password123@localhost:3306/SmartSusChef\"\n",
    "    \n",
    "    try:\n",
    "        engine = create_engine(DB_URL)\n",
    "        query = \"\"\"\n",
    "        SELECT s.Date as date, r.Name as dish, s.QuantitySold as sales\n",
    "        FROM Sales s JOIN Recipes r ON s.RecipeId = r.Id\n",
    "        ORDER BY s.Date ASC\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(query, engine)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        print(f\"‚úÖ Loaded {len(df)} rows from MySQL.\")\n",
    "        return df\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è MySQL Connection failed (or not configured). Falling back to CSV.\")\n",
    "        df = pd.read_csv('food_sales_eng.csv')\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
    "        return df.sort_values('date')\n",
    "\n",
    "def sanitize_sparse_data(df, country_code):\n",
    "    \"\"\"\n",
    "    The 'Anti-Lazy Employee' Logic.\n",
    "    \"\"\"\n",
    "    # 1. Create a perfect timeline (Mon, Tue, Wed...) with no missing dates\n",
    "    all_dates = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')\n",
    "    df = df.set_index('date').reindex(all_dates)\n",
    "    \n",
    "    # 2. Check for \"Weak Days\" (e.g., Tuesdays with < 15 records) - \n",
    "    # To change the logic because we're using overwritting of entries\n",
    "    day_counts = df.groupby(df.index.dayofweek)['sales'].count()\n",
    "    weak_days = day_counts[day_counts < 15].index \n",
    "    if len(weak_days) > 0:\n",
    "        # Nuke the bad data (Set to NaN)\n",
    "        df.loc[df['date'].dt.dayofweek.isin(weak_days), 'sales'] = np.nan\n",
    "    \n",
    "    # 3. INTERPOLATION (The Fix)\n",
    "    # Draw a line between the valid days to fill the gaps\n",
    "    df['sales'] = df['sales'].interpolate(method='time').fillna(0)\n",
    "\n",
    "    # 4. Feature Gaps\n",
    "    # A. Fill Dish Name\n",
    "    if 'dish' in df.columns:\n",
    "        valid_name = df['dish'].dropna().iloc[0] if not df['dish'].dropna().empty else \"Unknown\"\n",
    "        df['dish'] = valid_name\n",
    "\n",
    "    # B. Fill Rain (Interpolate from adjacent days)\n",
    "    if 'rain_lunch_vol' in df.columns:\n",
    "        df['rain_lunch_vol'] = df['rain_lunch_vol'].interpolate(method='time').fillna(method='bfill').fillna(method='ffill')\n",
    "    else:\n",
    "        df['rain_lunch_vol'] = 0.0\n",
    "\n",
    "    # C. Fill Holidays (Recalculate for the new dates)\n",
    "    if country_code == 'SG':\n",
    "        local_holidays = holidays.SG(years=[2024, 2025, 2026])\n",
    "    else:\n",
    "        local_holidays = holidays.CN(years=[2024, 2025, 2026])\n",
    "    \n",
    "    # Re-apply holiday logic to the index\n",
    "    df['is_public_holiday'] = df.index.to_series().apply(lambda x: 1 if x in local_holidays else 0)\n",
    "\n",
    "    # D. Recalculate Calendar Features\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    # 5. CLEANUP\n",
    "    # Now we reset the index so 'date' becomes a normal column again for the rest of the script\n",
    "    df = df.reset_index().rename(columns={'index': 'date'})\n",
    "    \n",
    "    # 6. Restore the Dish Name (since reindexing wiped it)\n",
    "    if 'dish' in df.columns: \n",
    "        df['dish'] = df['dish'].dropna().iloc[0]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Step 3: The Evaluator (Backtesting)\n",
    "Before we trust a model, we must test it. \n",
    "We calculate **MAE (Mean Absolute Error)**: *\"On average, how many plates are we wrong by?\"*\n",
    "\n",
    "**Logic:**\n",
    "1. Hide the last 30 days of sales.\n",
    "2. Train model on the past.\n",
    "3. Ask model to predict those hidden 30 days.\n",
    "4. Compare Prediction vs. Reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dish_name, df, model_type, country_code):\n",
    "    # 1. Split Data (Train vs Test)\n",
    "    cutoff_date = df['date'].max() - pd.Timedelta(days=30)\n",
    "    train = df[df['date'] < cutoff_date].copy()\n",
    "    test = df[df['date'] >= cutoff_date].copy()\n",
    "    \n",
    "    if len(test) < 1:\n",
    "        return 999.0 # Impossible to test\n",
    "\n",
    "    predicted_values = []\n",
    "    \n",
    "    # --- PROPHET LOGIC ---\n",
    "    if model_type == 'prophet':\n",
    "        p_train = train[['date', 'sales', 'rain_lunch_vol', 'is_public_holiday']].rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "        m = Prophet(daily_seasonality=True)\n",
    "        # Use Country-Specific Holidays\n",
    "        try: m.add_country_holidays(country_name=country_code) \n",
    "        except: pass\n",
    "        m.add_regressor('rain_lunch_vol')\n",
    "        m.fit(p_train)\n",
    "        \n",
    "        p_test = test[['date', 'rain_lunch_vol', 'is_public_holiday']].rename(columns={'date': 'ds'})\n",
    "        forecast = m.predict(p_test)\n",
    "        predicted_values = forecast['yhat'].values\n",
    "\n",
    "    # --- CATBOOST LOGIC ---\n",
    "    elif model_type == 'catboost':\n",
    "        features = ['day_of_week', 'month', 'is_public_holiday', 'rain_lunch_vol']\n",
    "        cat_indices = ['day_of_week', 'month', 'is_public_holiday']\n",
    "        \n",
    "        m = CatBoostRegressor(iterations=300, depth=6, cat_features=cat_indices, verbose=False)\n",
    "        m.fit(train[features], train['sales'])\n",
    "        \n",
    "        predicted_values = m.predict(test[features])\n",
    "        \n",
    "    # 2. Calculate Error\n",
    "    predicted_values = np.maximum(predicted_values, 0) # No negative food\n",
    "    mae = mean_absolute_error(test['sales'], predicted_values)\n",
    "    \n",
    "    return round(mae, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: The Main Loop (Train, Evaluate, Save)\n",
    "This runs for every dish on the menu. \n",
    "It prints the \"Champion\" (Lowest Error) but saves **BOTH** models so the API has a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(df, country_code):\n",
    "    unique_dishes = df['dish'].unique()\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING TRAINING FOR {len(unique_dishes)} DISHES IN {country_code}\")\n",
    "    print(f\"{'DISH NAME':<35} | {'PROPHET MAE':<12} | {'CATBOOST MAE':<12} | {'WINNER':<10}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for dish_name in unique_dishes:\n",
    "        # 1. Isolate Dish Data\n",
    "        dish_data = df[df['dish'] == dish_name].copy()\n",
    "        dish_data = sanitize_sparse_data(dish_data, country_code)\n",
    "        \n",
    "        # 2. EVALUATION PHASE (Who is better?)\n",
    "        p_error = evaluate_model(dish_name, dish_data, 'prophet', country_code)\n",
    "        c_error = evaluate_model(dish_name, dish_data, 'catboost', country_code)\n",
    "        \n",
    "        winner = \"PROPHET\" if p_error < c_error else \"CATBOOST\"\n",
    "        print(f\"{dish_name:<35} | {p_error:<12} | {c_error:<12} | {winner:<10}\")\n",
    "\n",
    "        # 3. PRODUCTION TRAINING PHASE\n",
    "        # We retrain BOTH models on 100% of the data (no split) to maximize accuracy for tomorrow.\n",
    "        \n",
    "        # Train Prophet\n",
    "        p_df = dish_data[['date', 'sales', 'rain_lunch_vol', 'is_public_holiday']].rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "        m_prophet = Prophet(daily_seasonality=True)\n",
    "        try: m_prophet.add_country_holidays(country_name=country_code)\n",
    "        except: pass\n",
    "        m_prophet.add_regressor('rain_lunch_vol')\n",
    "        m_prophet.fit(p_df)\n",
    "        with open(f'models/prophet_{dish_name}.pkl', 'wb') as f: pickle.dump(m_prophet, f)\n",
    "\n",
    "        # Train CatBoost\n",
    "        features = ['day_of_week', 'month', 'is_public_holiday', 'rain_lunch_vol']\n",
    "        cat_indices = ['day_of_week', 'month', 'is_public_holiday']\n",
    "        m_cat = CatBoostRegressor(iterations=300, depth=6, cat_features=cat_indices, verbose=False)\n",
    "        m_cat.fit(dish_data[features], dish_data['sales'])\n",
    "        with open(f'models/catboost_{dish_name}.pkl', 'wb') as f: pickle.dump(m_cat, f)\n",
    "            \n",
    "    print(f\"{'='*80}\\n‚úÖ All models saved to /models folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prediction API\n",
    "This simulates the API call. Loads saved model and predicts for a specific future date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction API\n",
    "def get_prediction(dish, date_str, lat, lon, rain_forecast=0, model='prophet'):\n",
    "    \"\"\"\n",
    "    Predicts demand for a future date.\n",
    "    \"\"\"\n",
    "    dt = pd.to_datetime(date_str)\n",
    "    country = get_country_code(lat, lon)\n",
    "    \n",
    "    # 1. Rebuild Context\n",
    "    local_hols = holidays.SG() if country == 'SG' else holidays.CN()\n",
    "    is_hol = 1 if dt in local_hols else 0\n",
    "    \n",
    "    # Input DataFrame\n",
    "    future = pd.DataFrame({\n",
    "        'ds': [dt],\n",
    "        'rain_lunch_vol': [rain_forecast],\n",
    "        'is_public_holiday': [is_hol],\n",
    "        'day_of_week': [dt.dayofweek],\n",
    "        'month': [dt.month]\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        # PROPHET PATH\n",
    "        if model == 'prophet':\n",
    "            with open(f'models/prophet_{dish}.pkl', 'rb') as f: m = pickle.load(f)\n",
    "            fcst = m.predict(future)\n",
    "            qty = int(max(0, fcst['yhat'].values[0]))\n",
    "            expl = {\n",
    "                \"Base\": round(fcst['trend'].values[0], 1),\n",
    "                \"Holiday\": round(fcst['holidays'].values[0], 1),\n",
    "                \"Weather\": round(fcst['extra_regressors_additive'].values[0], 1)\n",
    "            }\n",
    "            \n",
    "        # CATBOOST PATH\n",
    "        elif model == 'catboost':\n",
    "            with open(f'models/catboost_{dish}.pkl', 'rb') as f: m = pickle.load(f)\n",
    "            cols = ['day_of_week', 'month', 'is_public_holiday', 'rain_lunch_vol']\n",
    "            pred = m.predict(future[cols])[0]\n",
    "            qty = int(max(0, pred))\n",
    "            \n",
    "            # SHAP Explanation\n",
    "            ex = shap.TreeExplainer(m)\n",
    "            sv = ex.shap_values(future[cols])\n",
    "            expl = {\n",
    "                \"Base\": round(ex.expected_value, 1),\n",
    "                \"Holiday\": round(sv[0][2], 1), # Index 2 is Holiday\n",
    "                \"Weather\": round(sv[0][3], 1)  # Index 3 is Rain\n",
    "                }\n",
    "            \n",
    "        return {\"Dish\": dish, \"Date\": date_str, \"Prediction\": qty, \"Explanation\": expl}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"Error\": f\"Model not found for {dish}. {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ Step 6: Execution Block\n",
    "This simulates the command you would run from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fetch Data\n",
    "raw_df = fetch_training_data()\n",
    "\n",
    "# 2. Define Location (e.g., Shanghai coordinates)\n",
    "lat_input, lon_input = 31.23, 121.47 \n",
    "\n",
    "# 3. Run Pipeline\n",
    "enriched_df, country = add_local_context(raw_df, lat_input, lon_input)\n",
    "train_and_evaluate(enriched_df, country)\n",
    "\n",
    "# 4. Test Predictions\n",
    "target_date = '2026-05-20'\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"üîÆ FORECAST REPORT | DATE: {target_date} | LOCATION: {country}\")\n",
    "print(f\"{'='*90}\")\n",
    "# Header Row\n",
    "print(f\"{'DISH NAME':<40} | {'PREDICT':<8} | {'BASE':<8} | {'HOLIDAY':<8} | {'WEATHER':<8}\")\n",
    "print(f\"{'-'*105}\")\n",
    "\n",
    "unique_dishes = raw_df['dish'].unique()\n",
    "\n",
    "for dish in unique_dishes:\n",
    "    result = get_prediction(\n",
    "        dish=dish, \n",
    "        date_str=target_date, \n",
    "        lat=lat_input, \n",
    "        lon=lon_input, \n",
    "        rain_forecast=10.0, # Simulating a rainy day\n",
    "        model='prophet'\n",
    "    )\n",
    "    \n",
    "    if \"Error\" not in result:\n",
    "        qty = result['Prediction']\n",
    "        # Extract explanation details\n",
    "        base = result['Explanation']['Base']\n",
    "        hol = result['Explanation']['Holiday']\n",
    "        weather = result['Explanation']['Weather']\n",
    "        \n",
    "        # Print Row\n",
    "        print(f\"{dish:<40} | {qty:<8} | {base:<8} | {hol:<8} | {weather:<8}\")\n",
    "    else:\n",
    "        print(f\"{dish:<40} | ERROR: {result['Error']}\")\n",
    "\n",
    "print(f\"{'='*105}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
