{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmartSus Chef: The Universal Predictive Engine\n",
    "**Version:** 2.0 (Production Ready) | **Context:** Singapore & China | **Architecture:** Champion-Challenger\n",
    "\n",
    "## üìñ How to read this Notebook\n",
    "This engine is designed to predict food demand for F&B operators. It follows a strict pipeline:\n",
    "1.  **Context Detection:** Where is the restaurant? (SG or CN?) -> Load correct Holidays/Weather.\n",
    "2.  **Data Ingestion:** Fetch sales history from MySQL (or CSV fallback).\n",
    "3.  **Sanitation:** Fix \"Lazy Employee\" data (missing days) using interpolation.\n",
    "4.  **Evaluation (The Battle):** Hide the last 30 days, train on the past, and see which model guesses the hidden days better.\n",
    "5.  **Production Training:** Retrain BOTH models on 100% of data so they are ready for tomorrow.\n",
    "6.  **Prediction:** Serve the forecast via API logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- IMPORTS & SETUP ---\n# We import standard data libraries (pandas/numpy) and our ML models (Prophet/CatBoost).\nimport pandas as pd\nimport numpy as np\nimport holidays\nimport pickle\nimport os\nimport shap\nfrom sqlalchemy import create_engine\nfrom prophet import Prophet\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport warnings\n\nwarnings.filterwarnings('ignore') # Keep the output clean\n\nprint(\"‚úÖ Libraries loaded successfully.\")"
  },
  {
   "cell_type": "code",
   "source": "# --- CONFIGURATION ---\nN_CV_FOLDS = 3            # Time-series CV folds (increase when data grows)\nTEST_WINDOW_DAYS = 30     # Days per test fold\nMIN_TRAIN_DAYS = 60       # Minimum training data for first fold\nRANDOM_SEED = 42\nTREE_DEPTH_GRID = [3, 4, 6]\nHOLIDAY_YEARS = [2024, 2025, 2026]\n\n# Feature lists for tree-based models (CatBoost/XGBoost).\n# SHAP grouping depends on this order: Seasonality[0:2], Holiday[2], Weather[3:5], Lags[5:10]\nTREE_FEATURES = ['day_of_week', 'month', 'is_public_holiday',\n                 'rain_lunch_vol', 'temperature',\n                 'lag_1', 'lag_7', 'rolling_mean_7', 'rolling_mean_14', 'lag_same_weekday_avg']\nTREE_CAT_FEATURES = ['day_of_week', 'month', 'is_public_holiday']\n\ndef safe_filename(name):\n    \"\"\"Sanitize dish name for use as a filename.\"\"\"\n    return name.replace(' ', '_').replace('-', '_').replace('/', '_')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìç Step 1: Context Awareness (Location Logic)\n",
    "The model needs to know if it is in **Singapore** (Tropical, Hari Raya) or **China** (4-Seasons, Lunar New Year).\n",
    "We determine this automatically using the restaurant's GPS coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_country_code(lat, lon):\n    \"\"\"\n    Simple Bounding Box Logic.\n    If the coordinates are inside Singapore box, return 'SG'. Else, default to 'CN'.\n    \"\"\"\n    if (1.1 <= lat <= 1.5) and (103.5 <= lon <= 104.1):\n        return 'SG'\n    return 'CN'\n\ndef estimate_temperature(date, country_code):\n    \"\"\"\n    Simulate temperature for a given date and country.\n    Uses date-based seed so each date gets a unique but reproducible value.\n    \n    TODO: Replace with real weather API (e.g., OpenWeatherMap) when available.\n          This function is the single place to swap in real data.\n    \"\"\"\n    rng = np.random.default_rng(RANDOM_SEED + date.toordinal())\n    m = date.month\n    if country_code == 'SG':\n        return rng.uniform(25, 34)\n    else:\n        if m in [12, 1, 2]:\n            return rng.uniform(2, 10)\n        elif m in [3, 4, 5]:\n            return rng.uniform(12, 25)\n        elif m in [6, 7, 8]:\n            return rng.uniform(26, 38)\n        else:\n            return rng.uniform(12, 25)\n\ndef add_local_context(df, lat, lon):\n    \"\"\"\n    Enriches the sales data with local context features (Holidays + Weather).\n    \"\"\"\n    country_code = get_country_code(lat, lon)\n    print(f\"üåç Detected Location: {country_code} (Lat: {lat}, Lon: {lon})\")\n    \n    df['day_of_week'] = df['date'].dt.dayofweek\n    df['month'] = df['date'].dt.month\n    \n    if country_code == 'SG':\n        local_holidays = holidays.SG(years=HOLIDAY_YEARS)\n    else:\n        local_holidays = holidays.CN(years=HOLIDAY_YEARS)\n        \n    df['is_public_holiday'] = df['date'].apply(lambda x: 1 if x in local_holidays else 0)\n    \n    rng = np.random.default_rng(RANDOM_SEED)\n    \n    def estimate_rain(row):\n        m = row['month']\n        if country_code == 'SG':\n            return rng.uniform(15, 60) if m in [11, 12, 1] else rng.uniform(5, 30)\n        else:\n            return rng.uniform(20, 80) if m in [6, 7, 8] else rng.uniform(5, 25)\n        \n    df['rain_lunch_vol'] = df.apply(estimate_rain, axis=1)\n    df['temperature'] = df['date'].apply(lambda d: estimate_temperature(d, country_code))\n    \n    return df, country_code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 2: Data Ingestion & Sanitation\n",
    "Here we connect to the database. Crucially, we apply the **\"Anti-Lazy Employee\"** fix.\n",
    "If the database has holes (missing days), the model will think sales were 0. We must fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def fetch_training_data():\n    \"\"\"\n    Tries to connect to MySQL. If it fails (e.g., you are testing locally without DB),\n    it falls back to 'food_sales.csv' so you can still run the code.\n    \"\"\"\n    DB_URL = \"mysql+pymysql://root:password123@localhost:3306/SmartSusChef\"\n    \n    try:\n        engine = create_engine(DB_URL)\n        query = \"\"\"\n        SELECT s.Date as date, r.Name as dish, s.QuantitySold as sales\n        FROM Sales s JOIN Recipes r ON s.RecipeId = r.Id\n        ORDER BY s.Date ASC\n        \"\"\"\n        df = pd.read_sql(query, engine)\n        df['date'] = pd.to_datetime(df['date'])\n        print(f\"‚úÖ Loaded {len(df)} rows from MySQL.\")\n        return df\n    except Exception:\n        print(\"‚ö†Ô∏è MySQL Connection failed (or not configured). Falling back to CSV.\")\n        df = pd.read_csv('food_sales_eng.csv')\n        df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n        return df.sort_values('date')\n\ndef sanitize_sparse_data(df, country_code):\n    \"\"\"\n    The 'Anti-Lazy Employee' Logic.\n    \"\"\"\n    all_dates = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')\n    df = df.set_index('date').reindex(all_dates)\n    \n    day_counts = df.groupby(df.index.dayofweek)['sales'].count()\n    expected_count = day_counts.mean()\n    weak_days = day_counts[day_counts < expected_count * 0.5].index\n    if len(weak_days) > 0:\n        df.loc[df.index.dayofweek.isin(weak_days), 'sales'] = np.nan\n    \n    df['sales'] = df['sales'].interpolate(method='time').fillna(0)\n\n    if 'dish' in df.columns:\n        df['dish'] = df['dish'].dropna().iloc[0] if not df['dish'].dropna().empty else \"Unknown\"\n\n    if 'rain_lunch_vol' in df.columns:\n        df['rain_lunch_vol'] = df['rain_lunch_vol'].interpolate(method='time').bfill().ffill()\n    else:\n        df['rain_lunch_vol'] = 0.0\n\n    if 'temperature' in df.columns:\n        df['temperature'] = df['temperature'].interpolate(method='time').bfill().ffill()\n    else:\n        df['temperature'] = 0.0\n\n    if country_code == 'SG':\n        local_holidays = holidays.SG(years=HOLIDAY_YEARS)\n    else:\n        local_holidays = holidays.CN(years=HOLIDAY_YEARS)\n    \n    df['is_public_holiday'] = df.index.to_series().apply(lambda x: 1 if x in local_holidays else 0)\n\n    df['day_of_week'] = df.index.dayofweek\n    df['month'] = df.index.month\n\n    df = df.reset_index().rename(columns={'index': 'date'})\n        \n    return df\n\ndef add_lag_features(df):\n    \"\"\"Add lag and rolling features for tree-based models.\"\"\"\n    df = df.sort_values('date')\n    df['lag_1'] = df['sales'].shift(1)\n    df['lag_7'] = df['sales'].shift(7)\n    df['rolling_mean_7'] = df['sales'].shift(1).rolling(7).mean()\n    df['rolling_mean_14'] = df['sales'].shift(1).rolling(14).mean()\n    df['lag_same_weekday_avg'] = (df['sales'].shift(7) + df['sales'].shift(14) +\n                                  df['sales'].shift(21) + df['sales'].shift(28)) / 4\n    df = df.dropna()\n    return df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Step 3: The Evaluator (Backtesting)\n",
    "Before we trust a model, we must test it. \n",
    "We calculate **MAE (Mean Absolute Error)**: *\"On average, how many plates are we wrong by?\"*\n",
    "\n",
    "**Logic:**\n",
    "1. Hide the last 30 days of sales.\n",
    "2. Train model on the past.\n",
    "3. Ask model to predict those hidden 30 days.\n",
    "4. Compare Prediction vs. Reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def _evaluate_tree(df, end_date, features, make_model, param_key):\n    \"\"\"Shared expanding-window CV + depth-tuning logic for tree-based models.\"\"\"\n    best_avg_mae = float('inf')\n    best_depth = TREE_DEPTH_GRID[0]\n    best_last_fold_preds = None\n\n    for depth in TREE_DEPTH_GRID:\n        fold_maes = []\n        last_fold_preds = None\n\n        for fold_i in range(N_CV_FOLDS, 0, -1):\n            test_end = end_date - pd.Timedelta(days=TEST_WINDOW_DAYS * (fold_i - 1))\n            test_start = test_end - pd.Timedelta(days=TEST_WINDOW_DAYS)\n\n            train = df[df['date'] < test_start].copy()\n            test = df[(df['date'] >= test_start) & (df['date'] < test_end)].copy()\n\n            train_span = (train['date'].max() - train['date'].min()).days if len(train) > 1 else 0\n            if train_span < MIN_TRAIN_DAYS or len(test) < 1:\n                continue\n\n            m = make_model(depth)\n            m.fit(train[features], train['sales'])\n            predicted_values = np.maximum(m.predict(test[features]), 0)\n\n            mae = mean_absolute_error(test['sales'], predicted_values)\n            fold_maes.append(mae)\n\n            last_fold_preds = {\n                'dates': test['date'].values,\n                'actual': test['sales'].values,\n                'predicted': predicted_values\n            }\n\n        if len(fold_maes) > 0:\n            avg_mae = np.mean(fold_maes)\n            if avg_mae < best_avg_mae:\n                best_avg_mae = avg_mae\n                best_depth = depth\n                best_last_fold_preds = last_fold_preds\n\n    if best_avg_mae == float('inf'):\n        return 999.0, None, {param_key: best_depth}\n\n    return round(best_avg_mae, 2), best_last_fold_preds, {param_key: best_depth}\n\n\ndef evaluate_model(df, model_type, country_code):\n    \"\"\"\n    Expanding-window time-series cross-validation.\n    Returns (average_mae, last_fold_predictions_dict, best_params).\n    \"\"\"\n    dates = df['date'].sort_values()\n    end_date = dates.max()\n\n    # --- PROPHET ---\n    if model_type == 'prophet':\n        fold_maes = []\n        last_fold_preds = None\n\n        for fold_i in range(N_CV_FOLDS, 0, -1):\n            test_end = end_date - pd.Timedelta(days=TEST_WINDOW_DAYS * (fold_i - 1))\n            test_start = test_end - pd.Timedelta(days=TEST_WINDOW_DAYS)\n\n            train = df[df['date'] < test_start].copy()\n            test = df[(df['date'] >= test_start) & (df['date'] < test_end)].copy()\n\n            train_span = (train['date'].max() - train['date'].min()).days if len(train) > 1 else 0\n            if train_span < MIN_TRAIN_DAYS or len(test) < 1:\n                continue\n\n            p_train = train[['date', 'sales', 'rain_lunch_vol', 'temperature']].rename(\n                columns={'date': 'ds', 'sales': 'y'})\n            m = Prophet(daily_seasonality=False)\n            try:\n                m.add_country_holidays(country_name=country_code)\n            except Exception:\n                pass\n            m.add_regressor('rain_lunch_vol')\n            m.add_regressor('temperature')\n            m.fit(p_train)\n\n            p_test = test[['date', 'rain_lunch_vol', 'temperature']].rename(columns={'date': 'ds'})\n            forecast = m.predict(p_test)\n            predicted_values = np.maximum(forecast['yhat'].values, 0)\n\n            mae = mean_absolute_error(test['sales'], predicted_values)\n            fold_maes.append(mae)\n\n            last_fold_preds = {\n                'dates': test['date'].values,\n                'actual': test['sales'].values,\n                'predicted': predicted_values\n            }\n\n        if len(fold_maes) == 0:\n            return 999.0, None, {}\n\n        avg_mae = round(np.mean(fold_maes), 2)\n        return avg_mae, last_fold_preds, {}\n\n    # --- CATBOOST (delegates to shared helper) ---\n    elif model_type == 'catboost':\n        def make_model(depth):\n            return CatBoostRegressor(iterations=300, depth=depth, cat_features=TREE_CAT_FEATURES,\n                                     random_seed=RANDOM_SEED, verbose=False)\n        return _evaluate_tree(df, end_date, TREE_FEATURES, make_model, 'depth')\n\n    # --- XGBOOST (delegates to shared helper) ---\n    elif model_type == 'xgboost':\n        def make_model(depth):\n            return XGBRegressor(n_estimators=300, max_depth=depth, learning_rate=0.05,\n                                random_state=RANDOM_SEED, n_jobs=-1)\n        return _evaluate_tree(df, end_date, TREE_FEATURES, make_model, 'max_depth')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: The Main Loop (Train, Evaluate, Save)\n",
    "This runs for every dish on the menu. \n",
    "It prints the \"Champion\" (Lowest Error) but saves **BOTH** models so the API has a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- TRAINING PIPELINE (SAVES CHAMPIONS) ---\ndef train_and_evaluate(df, country_code):\n    unique_dishes = df['dish'].unique()\n    os.makedirs('models', exist_ok=True)\n    \n    results_list = []\n    champion_map = {}\n    all_predictions = {}\n\n    print(f\"\\n{'='*95}\")\n    print(f\"STARTING 3-WAY TRAINING FOR {len(unique_dishes)} DISHES IN {country_code}\")\n    print(f\"{'DISH NAME':<35} | {'PROPHET':<10} | {'CATBOOST':<15} | {'XGBOOST':<15} | {'WINNER':<10}\")\n    print(f\"{'='*95}\")\n\n    for dish_name in unique_dishes:\n        safe_name = safe_filename(dish_name)\n\n        # 1. Isolate Dish Data\n        dish_data = df[df['dish'] == dish_name].copy()\n        dish_data = sanitize_sparse_data(dish_data, country_code)\n        dish_data_with_lags = add_lag_features(dish_data.copy())\n\n        # 2. EVALUATION PHASE\n        p_error, p_preds, p_params = evaluate_model(dish_data, 'prophet', country_code)\n        c_error, c_preds, c_params = evaluate_model(dish_data_with_lags, 'catboost', country_code)\n        x_error, x_preds, x_params = evaluate_model(dish_data_with_lags, 'xgboost', country_code)\n\n        # Determine Winner\n        scores = {'PROPHET': p_error, 'CATBOOST': c_error, 'XGBOOST': x_error}\n        winner = min(scores, key=scores.get)\n        winning_mae = scores[winner]\n        champion_map[dish_name] = {\n            'model': winner.lower(),\n            'mae': winning_mae,\n            'all_mae': {'prophet': p_error, 'catboost': c_error, 'xgboost': x_error}\n        }\n\n        preds_map = {'prophet': p_preds, 'catboost': c_preds, 'xgboost': x_preds}\n        all_predictions[dish_name] = preds_map\n\n        c_depth_str = f\"{c_error} (d={c_params.get('depth', '?')})\"\n        x_depth_str = f\"{x_error} (d={x_params.get('max_depth', '?')})\"\n        print(f\"{dish_name:<35} | {p_error:<10} | {c_depth_str:<15} | {x_depth_str:<15} | {winner:<10}\")\n\n        results_list.append({\n            'Dish': dish_name,\n            'Prophet MAE': p_error,\n            'CatBoost MAE': c_error,\n            'CB Depth': c_params.get('depth', '?'),\n            'XGBoost MAE': x_error,\n            'XGB Depth': x_params.get('max_depth', '?'),\n            'Winner': winner\n        })\n\n        # 3. PRODUCTION TRAINING PHASE\n\n        # Prophet\n        p_df = dish_data[['date', 'sales', 'rain_lunch_vol', 'temperature']].rename(\n            columns={'date': 'ds', 'sales': 'y'})\n        mp = Prophet(daily_seasonality=False)\n        try:\n            mp.add_country_holidays(country_name=country_code)\n        except Exception:\n            pass\n        mp.add_regressor('rain_lunch_vol')\n        mp.add_regressor('temperature')\n        mp.fit(p_df)\n        with open(f'models/prophet_{safe_name}.pkl', 'wb') as f:\n            pickle.dump(mp, f)\n\n        # CatBoost (tuned depth)\n        cb_depth = c_params.get('depth', 6)\n        mc = CatBoostRegressor(iterations=300, depth=cb_depth, cat_features=TREE_CAT_FEATURES,\n                               random_seed=RANDOM_SEED, verbose=False)\n        mc.fit(dish_data_with_lags[TREE_FEATURES], dish_data_with_lags['sales'])\n        with open(f'models/catboost_{safe_name}.pkl', 'wb') as f:\n            pickle.dump(mc, f)\n\n        # XGBoost (tuned depth)\n        xgb_depth = x_params.get('max_depth', 6)\n        mx = XGBRegressor(n_estimators=300, max_depth=xgb_depth, learning_rate=0.05,\n                          random_state=RANDOM_SEED, n_jobs=-1)\n        mx.fit(dish_data_with_lags[TREE_FEATURES], dish_data_with_lags['sales'])\n        with open(f'models/xgboost_{safe_name}.pkl', 'wb') as f:\n            pickle.dump(mx, f)\n\n        # Save recent sales history for lag computation at prediction time\n        recent_sales = dish_data[['date', 'sales']].tail(28).copy()\n        with open(f'models/recent_sales_{safe_name}.pkl', 'wb') as f:\n            pickle.dump(recent_sales, f)\n\n    # SAVE THE REGISTRY\n    with open('models/champion_registry.pkl', 'wb') as f:\n        pickle.dump(champion_map, f)\n\n    clear_model_cache()\n\n    print(f\"{'='*95}\\n‚úÖ All models saved. Champion Registry updated.\")\n    return pd.DataFrame(results_list), all_predictions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prediction API\n",
    "This simulates the API call. Loads saved model and predicts for a specific future date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- MODEL CACHE ---\n_model_cache = {}\n\ndef _load_cached(filepath):\n    if filepath not in _model_cache:\n        with open(filepath, 'rb') as f:\n            _model_cache[filepath] = pickle.load(f)\n    return _model_cache[filepath]\n\ndef clear_model_cache():\n    _model_cache.clear()\n\ndef _predict_tree(model_obj, future, cols, dish_mae):\n    \"\"\"Shared prediction + SHAP explanation logic for tree models.\"\"\"\n    pred = float(model_obj.predict(future[cols])[0])\n    qty = int(max(0, pred))\n    pred_lower = int(max(0, pred - dish_mae))\n    pred_upper = int(pred + dish_mae)\n\n    try:\n        ex = shap.TreeExplainer(model_obj)\n        sv = ex.shap_values(future[cols])[0]\n        base = float(ex.expected_value)\n        # SHAP grouping matches TREE_FEATURES order:\n        # Seasonality: day_of_week(0) + month(1)\n        seasonality = float(sv[0] + sv[1])\n        # Holiday: is_public_holiday(2)\n        holiday = float(sv[2])\n        # Weather: rain_lunch_vol(3) + temperature(4)\n        weather = float(sv[3] + sv[4])\n        # Lags: indices 5..9\n        lags = float(sv[5] + sv[6] + sv[7] + sv[8] + sv[9])\n        expl = {\n            \"Trend\": round(base + lags, 1),\n            \"Seasonality\": round(seasonality, 1),\n            \"Holiday\": round(holiday, 1),\n            \"Weather\": round(weather, 1)\n        }\n    except Exception:\n        expl = {\"Trend\": round(pred, 1), \"Seasonality\": 0.0,\n                \"Holiday\": 0.0, \"Weather\": 0.0}\n\n    return qty, pred_lower, pred_upper, expl\n\n# --- PREDICTION API (AUTO-SELECT) ---\ndef get_prediction(dish, date_str, lat, lon, rain_forecast=0, model='auto'):\n    \"\"\"\n    Predicts using the BEST model for the specific dish (unless overridden).\n    Returns prediction with MAE-based confidence intervals and explanation.\n    CI semantics: [prediction - MAE, prediction + MAE] for all model types.\n    \"\"\"\n    dt = pd.to_datetime(date_str)\n    country = get_country_code(lat, lon)\n    safe_name = safe_filename(dish)\n\n    dish_mae = 0.0\n\n    # 1. REGISTRY LOOKUP (always, for MAE ‚Äî even when model is manually specified)\n    try:\n        registry = _load_cached('models/champion_registry.pkl')\n        if model == 'auto':\n            model = registry[dish]['model']\n        dish_mae = registry[dish]['all_mae'].get(model, 0.0)\n    except Exception:\n        if model == 'auto':\n            model = 'prophet'\n\n    # 2. Rebuild Context\n    local_hols = holidays.SG() if country == 'SG' else holidays.CN()\n    is_hol = 1 if dt in local_hols else 0\n    temp = estimate_temperature(dt, country)\n\n    future = pd.DataFrame({\n        'ds': [dt],\n        'rain_lunch_vol': [rain_forecast],\n        'temperature': [temp],\n        'is_public_holiday': [is_hol],\n        'day_of_week': [dt.dayofweek],\n        'month': [dt.month]\n    })\n\n    # 3. For tree models, compute lag features from recent sales history\n    if model in ('catboost', 'xgboost'):\n        try:\n            recent = _load_cached(f'models/recent_sales_{safe_name}.pkl')\n            sales_vals = recent['sales'].values\n            future['lag_1'] = sales_vals[-1] if len(sales_vals) >= 1 else 0\n            future['lag_7'] = sales_vals[-7] if len(sales_vals) >= 7 else 0\n            future['rolling_mean_7'] = np.mean(sales_vals[-7:]) if len(sales_vals) >= 7 else np.mean(sales_vals)\n            future['rolling_mean_14'] = np.mean(sales_vals[-14:]) if len(sales_vals) >= 14 else np.mean(sales_vals)\n            weekday_vals = []\n            for w in [7, 14, 21, 28]:\n                if len(sales_vals) >= w:\n                    weekday_vals.append(sales_vals[-w])\n            future['lag_same_weekday_avg'] = np.mean(weekday_vals) if weekday_vals else 0\n        except Exception:\n            future['lag_1'] = 0\n            future['lag_7'] = 0\n            future['rolling_mean_7'] = 0\n            future['rolling_mean_14'] = 0\n            future['lag_same_weekday_avg'] = 0\n\n    try:\n        # --- PROPHET ---\n        if model == 'prophet':\n            mp = _load_cached(f'models/prophet_{safe_name}.pkl')\n            fcst = mp.predict(future[['ds', 'rain_lunch_vol', 'temperature']])\n            yhat = fcst['yhat'].values[0]\n            qty = int(max(0, yhat))\n\n            pred_lower = int(max(0, yhat - dish_mae))\n            pred_upper = int(yhat + dish_mae)\n\n            trend = fcst['trend'].values[0]\n            holiday = fcst['holidays'].values[0]\n            weather = fcst['extra_regressors_additive'].values[0]\n            seasonality = yhat - trend - holiday - weather\n\n            expl = {\n                \"Trend\": round(trend, 1),\n                \"Seasonality\": round(seasonality, 1),\n                \"Holiday\": round(holiday, 1),\n                \"Weather\": round(weather, 1)\n            }\n\n        # --- TREE MODELS (shared logic) ---\n        elif model in ('catboost', 'xgboost'):\n            tree_model = _load_cached(f'models/{model}_{safe_name}.pkl')\n            qty, pred_lower, pred_upper, expl = _predict_tree(tree_model, future, TREE_FEATURES, dish_mae)\n\n        return {\n            \"Dish\": dish,\n            \"Date\": date_str,\n            \"Model Used\": model.upper(),\n            \"Prediction\": qty,\n            \"Prediction_Lower\": pred_lower,\n            \"Prediction_Upper\": pred_upper,\n            \"Explanation\": expl\n        }\n\n    except Exception as e:\n        return {\"Error\": f\"Model error for {dish}: {str(e)}\"}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ Step 6: Execution Block\n",
    "This simulates the command you would run from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- EXECUTION TEST ---\n\n# 1. Load Data\nraw_df = fetch_training_data()\n\n# 2. Define Location\nlat_in, lon_in = 31.23, 121.47 \n\n# 3. Add Context\nenriched_df, country = add_local_context(raw_df, lat_in, lon_in)\n\n# 4. Run Training Pipeline\nresults_table, all_predictions = train_and_evaluate(enriched_df, country)\n\n# 5. Show Leaderboard\nprint(f\"\\n{'='*50}\")\nprint(f\"MODEL LEADERBOARD (Lower MAE is Better)\")\nprint(f\"{'='*50}\")\ndisplay(results_table)"
  },
  {
   "cell_type": "code",
   "source": "# --- VISUALIZATION A: MAE Comparison Bar Chart ---\nfig, ax = plt.subplots(figsize=(16, 6))\n\ndishes = results_table['Dish']\nx = np.arange(len(dishes))\nwidth = 0.25\n\nbars_p = ax.bar(x - width, results_table['Prophet MAE'], width, label='Prophet', color='#4C72B0')\nbars_c = ax.bar(x, results_table['CatBoost MAE'], width, label='CatBoost', color='#DD8452')\nbars_x = ax.bar(x + width, results_table['XGBoost MAE'], width, label='XGBoost', color='#55A868')\n\n# Highlight the winner for each dish with a star marker\nfor i, row in results_table.iterrows():\n    winner_mae = min(row['Prophet MAE'], row['CatBoost MAE'], row['XGBoost MAE'])\n    if row['Winner'] == 'PROPHET':\n        offset = -width\n    elif row['Winner'] == 'CATBOOST':\n        offset = 0\n    else:\n        offset = width\n    ax.plot(x[i] + offset, winner_mae, marker='*', color='gold', markersize=14, zorder=5)\n\nax.set_xlabel('Dish')\nax.set_ylabel('MAE (plates)')\nax.set_title('Model MAE Comparison by Dish (lower is better)')\nax.set_xticks(x)\nax.set_xticklabels(dishes, rotation=45, ha='right', fontsize=8)\nax.legend()\nax.yaxis.set_minor_locator(ticker.AutoMinorLocator())\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --- VISUALIZATION B: Actual vs Predicted (Last Fold, Winning Model) ---\nn_dishes = len(results_table)\nncols = 4\nnrows = int(np.ceil(n_dishes / ncols))\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 4 * nrows), squeeze=False)\n\nfor idx, (_, row) in enumerate(results_table.iterrows()):\n    ax = axes[idx // ncols][idx % ncols]\n    dish = row['Dish']\n    winner = row['Winner'].lower()\n    \n    preds = all_predictions.get(dish, {}).get(winner)\n    if preds is not None:\n        dates = pd.to_datetime(preds['dates'])\n        ax.plot(dates, preds['actual'], label='Actual', color='#333333', linewidth=1.5)\n        ax.plot(dates, preds['predicted'], label='Predicted', color='#E24A33', linewidth=1.5, linestyle='--')\n        ax.fill_between(dates, preds['actual'], preds['predicted'], alpha=0.15, color='#E24A33')\n    \n    ax.set_title(f\"{dish}\\n({winner.upper()})\", fontsize=8, fontweight='bold')\n    ax.tick_params(axis='x', rotation=30, labelsize=6)\n    ax.tick_params(axis='y', labelsize=7)\n    if idx == 0:\n        ax.legend(fontsize=7)\n\n# Hide unused subplots\nfor idx in range(n_dishes, nrows * ncols):\n    axes[idx // ncols][idx % ncols].set_visible(False)\n\nfig.suptitle('Actual vs Predicted Sales (Last CV Fold, Winning Model)', fontsize=13, y=1.01)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --- PREDICTIONS: Forecast for Every Dish ---\nforecast_date = '2026-05-20'\nrain_input = 10.0\n\npredictions = []\nfor dish_name in enriched_df['dish'].unique():\n    res = get_prediction(\n        dish=dish_name,\n        date_str=forecast_date,\n        lat=lat_in, lon=lon_in,\n        rain_forecast=rain_input\n    )\n    if 'Error' not in res:\n        predictions.append({\n            'Dish': res['Dish'],\n            'Predicted Qty': res['Prediction'],\n            'Lower': res['Prediction_Lower'],\n            'Upper': res['Prediction_Upper'],\n            'Model': res['Model Used'],\n            'Trend': res['Explanation']['Trend'],\n            'Seasonality': res['Explanation']['Seasonality'],\n            'Holiday': res['Explanation']['Holiday'],\n            'Weather': res['Explanation']['Weather']\n        })\n\npred_df = pd.DataFrame(predictions)\n\nprint(f\"Forecast for: {forecast_date} | Rain: {rain_input}mm\")\nprint(\"Explanation: Trend + Seasonality + Holiday + Weather = Predicted Qty\")\nprint(f\"{'='*90}\")\ndisplay(pred_df)\n\n# Bar chart of predicted quantities with confidence interval error bars\nfig, ax = plt.subplots(figsize=(16, 6))\ncolors_map = {'PROPHET': '#4C72B0', 'CATBOOST': '#DD8452', 'XGBOOST': '#55A868'}\nbar_colors = [colors_map.get(m, '#999999') for m in pred_df['Model']]\n\n# Compute asymmetric error bars from Lower/Upper\nyerr_lower = pred_df['Predicted Qty'] - pred_df['Lower']\nyerr_upper = pred_df['Upper'] - pred_df['Predicted Qty']\nyerr = [yerr_lower.values, yerr_upper.values]\n\nbars = ax.bar(range(len(pred_df)), pred_df['Predicted Qty'], color=bar_colors,\n              yerr=yerr, capsize=3, error_kw={'elinewidth': 1, 'capthick': 1, 'color': '#555555'})\n\nax.set_xticks(range(len(pred_df)))\nax.set_xticklabels(pred_df['Dish'], rotation=45, ha='right', fontsize=8)\nax.set_ylabel('Predicted Quantity (plates)')\nax.set_title(f'Predicted Sales per Dish ‚Äî {forecast_date} (with Confidence Intervals)')\n\nfor bar, qty, lo, hi in zip(bars, pred_df['Predicted Qty'], pred_df['Lower'], pred_df['Upper']):\n    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + (hi - qty) + 1,\n            f\"{qty} [{lo}-{hi}]\", ha='center', va='bottom', fontsize=7, fontweight='bold')\n\nfrom matplotlib.patches import Patch\nlegend_patches = [Patch(color=c, label=m) for m, c in colors_map.items()]\nax.legend(handles=legend_patches, title='Model Used')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}