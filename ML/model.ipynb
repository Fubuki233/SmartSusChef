{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SmartSus Chef: The Universal Predictive Engine\n**Version:** 3.0 (Production Ready) | **Context:** Singapore & China | **Architecture:** Champion-Challenger\n\n## How to read this Notebook\nThis notebook runs a robust, parallelized ML pipeline to predict food demand. It acts as a high-level **orchestrator**, delegating the complex implementation details to the `training_logic.py` module.\n\n### The End-to-End Workflow:\n1.  **Context Detection:** Automatically determines the restaurant's location (e.g., SG or CN) to load the correct holiday and weather data.\n2.  **Data Ingestion:** Fetches the raw sales history from a database or a fallback CSV file.\n3.  **Data Cleaning & Sanitation:** Aggregates data to have one record per dish-day and fills any gaps from missing sales days.\n4.  **Backtesting & Champion Selection:** For each dish, all three models (Prophet, CatBoost, XGBoost) are tuned using Optuna and evaluated via time-series cross-validation to find the \"champion\" with the lowest error.\n5.  **Parallel Execution:** The entire evaluation for each dish is run in parallel on a separate CPU core to significantly speed up the training process.\n6.  **Production Training:** After a champion model is chosen, all three models are retrained on 100% of the data using the best-found parameters and saved to disk.\n7.  **Forecasting:** A 14-day rolling forecast is generated using the saved production models, complete with SHAP-based explanations for a model's reasoning."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- IMPORTS & SETUP ---\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport holidays\nimport shap\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Import core pipeline logic from our module\nfrom training_logic import (\n    PipelineConfig,\n    CFG,\n    process_dish,\n    fetch_training_data,\n    add_local_context,\n    get_country_code,\n    estimate_temperature,\n    safe_filename,\n)\n\nprint(\"Libraries loaded successfully.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pipeline Overview: From Raw Data to Trained Models\n\nThe core of this project lies in the `training_logic.py` module, which is responsible for the heavy lifting. The notebook simply orchestrates the execution of this logic. The process for each dish is as follows:\n\n### 1. Data Preparation & Feature Engineering\nFirst, the pipeline prepares a clean, feature-rich dataset.\n- **Context & Ingestion:** It begins by detecting the restaurant's location (`add_local_context`) and loading the complete sales history (`fetch_training_data`).\n- **Cleaning & Enrichment:** The raw data is then cleaned to fill in missing dates (`sanitize_sparse_data`) and enriched with dozens of predictive features like lags, rolling averages, and trend indicators (`add_lag_features`). This provides rich input for the tree-based models.\n\n### 2. Backtesting & Champion Selection\nNext, each model type is rigorously tested to find the best one for the job.\n- **Time-Series Cross-Validation:** Instead of a simple train-test split, we use expanding-window cross-validation (`_generate_cv_folds`), which is more robust for time-series data.\n- **Hyperparameter Tuning:** For each model, `Optuna` is used to automatically find the best hyperparameters (e.g., learning rate, tree depth), ensuring peak performance.\n- **Champion Crowning:** The model with the lowest Mean Absolute Error (MAE) across the validation folds is crowned the \"champion\" for that specific dish.\n\n### 3. The `process_dish` Worker Function\nThe entire data preparation and backtesting process is encapsulated within the `process_dish` function in `training_logic.py`. This function acts as a self-contained, parallel-ready worker that takes a dish name and returns the champion model, its performance metrics, and its ideal parameters. The cell below runs this function for all dishes."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 5: Multi-Day Prediction API (14-Day Rolling Forecast)\nThe prediction API now returns a **list of forecasts** for the next 14 days.\n\n- **Tree models** use a **recursive forecasting loop**: each day's prediction is appended to the history to compute lags for the next day.\n- **Prophet** uses its native `make_future_dataframe()` for multi-step prediction.\n- **Average-only dishes** return a flat-line forecast at the saved average.\n- SHAP explanations use **name-based feature grouping** via `config.feature_groups` for robustness."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- MODEL CACHE ---\n_model_cache = {}\n\ndef _load_cached(filepath):\n    if filepath not in _model_cache:\n        with open(filepath, 'rb') as f:\n            _model_cache[filepath] = pickle.load(f)\n    return _model_cache[filepath]\n\ndef clear_model_cache():\n    _model_cache.clear()\n\n\ndef _compute_lag_features_from_history(sales_history, dt, config):\n    \"\"\"Compute all lag/rolling features for a single forecast date given a sales history array.\"\"\"\n    vals = sales_history\n    n = len(vals)\n\n    features = {}\n    for lag in [1, 7, 14, 21, 28]:\n        features[f'lag_{lag}'] = vals[-lag] if n >= lag else 0.0\n\n    if n >= 8:\n        window = vals[-8:-1]  # shifted by 1\n        features['rolling_mean_7'] = np.mean(window)\n        features['rolling_std_7'] = np.std(window, ddof=1) if len(window) > 1 else 0.0\n    else:\n        features['rolling_mean_7'] = np.mean(vals) if n > 0 else 0.0\n        features['rolling_std_7'] = 0.0\n\n    if n >= 15:\n        window = vals[-15:-1]\n        features['rolling_mean_14'] = np.mean(window)\n        features['rolling_std_14'] = np.std(window, ddof=1) if len(window) > 1 else 0.0\n    else:\n        features['rolling_mean_14'] = np.mean(vals) if n > 0 else 0.0\n        features['rolling_std_14'] = 0.0\n\n    rm7 = features['rolling_mean_7']\n    rm14 = features['rolling_mean_14']\n    features['trend_ratio'] = rm7 / rm14 if rm14 != 0 else 1.0\n\n    if n >= 2:\n        features['expanding_mean'] = np.mean(vals[:-1])\n    else:\n        features['expanding_mean'] = np.mean(vals) if n > 0 else 0.0\n\n    weekday_vals = [vals[-s] for s in [7, 14, 21, 28] if n >= s]\n    features['lag_same_weekday_avg'] = np.mean(weekday_vals) if weekday_vals else 0.0\n    features['lag_same_weekday_std'] = np.std(weekday_vals, ddof=1) if len(weekday_vals) > 1 else 0.0\n\n    return features\n\n\ndef _predict_tree_multiday(model_obj, base_future_row, recent_sales_df, config, country_code, dish_mae):\n    \"\"\"\n    Recursive 14-day rolling forecast for tree-based models.\n    Returns list of {date, qty, lower, upper, explanation} dicts.\n    \"\"\"\n    results = []\n    sales_history = recent_sales_df['sales'].values.tolist()\n    start_date = base_future_row['ds'].iloc[0]\n\n    # Build feature name -> group mapping from config\n    feat_to_group = {}\n    for group_name, feat_list in config.feature_groups.items():\n        for feat in feat_list:\n            feat_to_group[feat] = group_name\n\n    for day_offset in range(config.forecast_horizon):\n        dt = start_date + pd.Timedelta(days=day_offset)\n\n        local_hols = holidays.SG(years=config.holiday_years) if country_code == 'SG' \\\n            else holidays.CN(years=config.holiday_years)\n        is_hol = 1 if dt in local_hols else 0\n        temp = estimate_temperature(dt, country_code)\n\n        lag_feats = _compute_lag_features_from_history(sales_history, dt, config)\n\n        row = {\n            'day_of_week': dt.dayofweek,\n            'month': dt.month,\n            'is_public_holiday': is_hol,\n            'rain_lunch_vol': base_future_row['rain_lunch_vol'].iloc[0],\n            'temperature': temp,\n        }\n        row.update(lag_feats)\n\n        future_df = pd.DataFrame([row])[config.tree_features]\n        pred = float(model_obj.predict(future_df)[0])\n        qty = int(max(0, pred))\n        pred_lower = int(max(0, pred - dish_mae))\n        pred_upper = int(pred + dish_mae)\n\n        # SHAP explanation with name-based grouping\n        try:\n            ex = shap.TreeExplainer(model_obj)\n            sv = ex.shap_values(future_df)[0]\n            base_val = float(ex.expected_value)\n            group_shap = {}\n            for i, feat_name in enumerate(config.tree_features):\n                group = feat_to_group.get(feat_name, \"Other\")\n                group_shap[group] = group_shap.get(group, 0.0) + float(sv[i])\n\n            expl = {\n                \"Trend\": round(base_val + group_shap.get(\"Lags/Trend\", 0.0), 1),\n                \"Seasonality\": round(group_shap.get(\"Seasonality\", 0.0), 1),\n                \"Holiday\": round(group_shap.get(\"Holiday\", 0.0), 1),\n                \"Weather\": round(group_shap.get(\"Weather\", 0.0), 1),\n            }\n        except Exception:\n            expl = {\"Trend\": round(pred, 1), \"Seasonality\": 0.0,\n                    \"Holiday\": 0.0, \"Weather\": 0.0}\n\n        results.append({\n            \"date\": dt.strftime('%Y-%m-%d'),\n            \"qty\": qty,\n            \"lower\": pred_lower,\n            \"upper\": pred_upper,\n            \"explanation\": expl\n        })\n\n        # Append prediction to history for next iteration\n        sales_history.append(max(0, pred))\n\n    return results\n\n\ndef get_prediction(dish, date_str, lat, lon, rain_forecast=0, model='auto', config=CFG):\n    \"\"\"\n    Multi-day prediction API.\n    Returns a list of dicts (one per forecast day, up to config.forecast_horizon days).\n    For average-only dishes, returns flat-line forecast.\n    \"\"\"\n    dt = pd.to_datetime(date_str)\n    country = get_country_code(lat, lon)\n    safe_name = safe_filename(dish)\n    dish_mae = 0.0\n\n    # Registry lookup\n    try:\n        registry = _load_cached(f'{config.model_dir}/champion_registry.pkl')\n        dish_info = registry[dish]\n        if model == 'auto':\n            model = dish_info['model']\n        dish_mae = dish_info['all_mae'].get(model, 0.0) if dish_info['all_mae'] else 0.0\n    except Exception:\n        if model == 'auto':\n            model = 'prophet'\n\n    # Average-only dishes\n    if model == 'average':\n        try:\n            avg_sales = _load_cached(f'{config.model_dir}/average_{safe_name}.pkl')\n        except Exception:\n            avg_sales = 0\n        results = []\n        for day_offset in range(config.forecast_horizon):\n            d = dt + pd.Timedelta(days=day_offset)\n            results.append({\n                \"Dish\": dish, \"Date\": d.strftime('%Y-%m-%d'),\n                \"Model Used\": \"AVERAGE\",\n                \"Prediction\": avg_sales,\n                \"Prediction_Lower\": avg_sales,\n                \"Prediction_Upper\": avg_sales,\n                \"Explanation\": {\"Trend\": float(avg_sales), \"Seasonality\": 0.0,\n                                \"Holiday\": 0.0, \"Weather\": 0.0}\n            })\n        return results\n\n    # Build base context row\n    local_hols = holidays.SG(years=config.holiday_years) if country == 'SG' \\\n        else holidays.CN(years=config.holiday_years)\n    is_hol = 1 if dt in local_hols else 0\n    temp = estimate_temperature(dt, country)\n\n    base_future = pd.DataFrame({\n        'ds': [dt],\n        'rain_lunch_vol': [rain_forecast],\n        'temperature': [temp],\n        'is_public_holiday': [is_hol],\n        'day_of_week': [dt.dayofweek],\n        'month': [dt.month]\n    })\n\n    try:\n        if model == 'prophet':\n            mp = _load_cached(f'{config.model_dir}/prophet_{safe_name}.pkl')\n            future_dates = mp.make_future_dataframe(periods=config.forecast_horizon)\n            future_dates = future_dates.tail(config.forecast_horizon).copy()\n            future_dates['rain_lunch_vol'] = rain_forecast\n            future_dates['temperature'] = future_dates['ds'].apply(\n                lambda d: estimate_temperature(d, country))\n            forecast = mp.predict(future_dates)\n\n            results = []\n            for _, row in forecast.iterrows():\n                yhat = row['yhat']\n                qty = int(max(0, yhat))\n                trend = row['trend']\n                holiday_val = row['holidays'] if 'holidays' in row else 0.0\n                weather = row['extra_regressors_additive'] if 'extra_regressors_additive' in row else 0.0\n                seasonality = yhat - trend - holiday_val - weather\n\n                results.append({\n                    \"Dish\": dish,\n                    \"Date\": row['ds'].strftime('%Y-%m-%d'),\n                    \"Model Used\": \"PROPHET\",\n                    \"Prediction\": qty,\n                    \"Prediction_Lower\": int(max(0, yhat - dish_mae)),\n                    \"Prediction_Upper\": int(yhat + dish_mae),\n                    \"Explanation\": {\n                        \"Trend\": round(trend, 1),\n                        \"Seasonality\": round(seasonality, 1),\n                        \"Holiday\": round(holiday_val, 1),\n                        \"Weather\": round(weather, 1)\n                    }\n                })\n            return results\n\n        elif model in ('catboost', 'xgboost'):\n            tree_model = _load_cached(f'{config.model_dir}/{model}_{safe_name}.pkl')\n            recent = _load_cached(f'{config.model_dir}/recent_sales_{safe_name}.pkl')\n\n            multiday = _predict_tree_multiday(\n                tree_model, base_future, recent, config, country, dish_mae)\n\n            results = []\n            for entry in multiday:\n                results.append({\n                    \"Dish\": dish,\n                    \"Date\": entry['date'],\n                    \"Model Used\": model.upper(),\n                    \"Prediction\": entry['qty'],\n                    \"Prediction_Lower\": entry['lower'],\n                    \"Prediction_Upper\": entry['upper'],\n                    \"Explanation\": entry['explanation']\n                })\n            return results\n\n    except Exception as e:\n        return [{\"Error\": f\"Model error for {dish}: {str(e)}\"}]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 6: Parallel Execution & Results\nRun all dishes in parallel using `ProcessPoolExecutor`. Each dish is independently processed across CPU cores.\nAfter completion, aggregate results into a leaderboard and save the champion registry."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- PARALLEL EXECUTION ---\nif __name__ == \"__main__\":\n    # 1. Load and prepare the master DataFrame\n    # This function also cleans the data by normalizing dates and aggregating sales.\n    raw_df = fetch_training_data()\n\n    # 2. Define global context for this run\n    lat_in, lon_in = 31.23, 121.47\n    CFG = PipelineConfig()\n    enriched_df, country = add_local_context(raw_df, lat_in, lon_in)\n\n    # 4. Run the full training pipeline in parallel for each dish\n    unique_dishes = enriched_df['dish'].unique()\n    results = []\n\n    print(f\"\\n{'='*95}\")\n    print(f\"STARTING PARALLEL TRAINING FOR {len(unique_dishes)} DISHES \"\n          f\"({CFG.max_workers} workers, {CFG.n_optuna_trials} Optuna trials each)\")\n    print(f\"{'='*95}\")\n\n    # Use ProcessPoolExecutor to run the `process_dish` function for each dish on a separate core\n    with ProcessPoolExecutor(max_workers=CFG.max_workers) as executor:\n        # Create a dictionary mapping future objects to dish names for easy lookup\n        futures = {\n            executor.submit(process_dish, dish, enriched_df, country, CFG): dish\n            for dish in unique_dishes\n        }\n        # Process results as they are completed\n        for future in as_completed(futures):\n            dish_name = futures[future]\n            try:\n                result = future.result()\n                results.append(result)\n                # Print real-time progress for each dish\n                if result['champion'] == 'average':\n                    print(f\"  {dish_name:<35} | AVG (short data) -> avg_sales={result['avg_sales']}\")\n                else:\n                    mae = result['mae']\n                    print(f\"  {dish_name:<35} | P={mae['prophet']:<7} C={mae['catboost']:<7} \"\n                          f\"X={mae['xgboost']:<7} -> {result['champion'].upper()}\")\n            except Exception as e:\n                print(f\"  {dish_name:<35} | ERROR: {e}\")\n\n    # 5. Aggregate and display the final results from all parallel runs\n    champion_map = {}\n    all_predictions = {}\n    results_rows = []\n\n    for r in results:\n        dish = r['dish']\n        champion_map[dish] = {\n            'model': r['champion'],\n            'mae': r.get('champion_mae', 0.0),\n            'all_mae': r['mae']\n        }\n        if r['backtest_preds'] is not None:\n            all_predictions[dish] = r['backtest_preds']\n\n        if r['champion'] == 'average':\n            results_rows.append({\n                'Dish': dish, 'Prophet MAE': '-', 'CatBoost MAE': '-',\n                'XGBoost MAE': '-', 'Winner': 'AVERAGE'\n            })\n        else:\n            results_rows.append({\n                'Dish': dish,\n                'Prophet MAE': r['mae']['prophet'],\n                'CatBoost MAE': r['mae']['catboost'],\n                'XGBoost MAE': r['mae']['xgboost'],\n                'Winner': r['champion'].upper()\n            })\n\n    with open(f'{CFG.model_dir}/champion_registry.pkl', 'wb') as f:\n        pickle.dump(champion_map, f)\n\n    clear_model_cache()\n\n    results_table = pd.DataFrame(results_rows)\n\n    print(f\"\\n{'='*50}\")\n    print(f\"MODEL LEADERBOARD (Lower MAE is Better)\")\n    print(f\"{'='*50}\")\n    display(results_table)"
  },
  {
   "cell_type": "code",
   "source": "# --- VISUALIZATION A: MAE Comparison Bar Chart ---\n# Filter to ML-trained dishes only (exclude average-only)\nml_rows = results_table[results_table['Winner'] != 'AVERAGE'].copy()\n\nif len(ml_rows) > 0:\n    fig, ax = plt.subplots(figsize=(16, 6))\n\n    dishes = ml_rows['Dish']\n    x = np.arange(len(dishes))\n    width = 0.25\n\n    bars_p = ax.bar(x - width, ml_rows['Prophet MAE'].astype(float), width,\n                    label='Prophet', color='#4C72B0')\n    bars_c = ax.bar(x, ml_rows['CatBoost MAE'].astype(float), width,\n                    label='CatBoost', color='#DD8452')\n    bars_x = ax.bar(x + width, ml_rows['XGBoost MAE'].astype(float), width,\n                    label='XGBoost', color='#55A868')\n\n    for i, (_, row) in enumerate(ml_rows.iterrows()):\n        p_mae = float(row['Prophet MAE'])\n        c_mae = float(row['CatBoost MAE'])\n        x_mae = float(row['XGBoost MAE'])\n        winner_mae = min(p_mae, c_mae, x_mae)\n        if row['Winner'] == 'PROPHET':\n            offset = -width\n        elif row['Winner'] == 'CATBOOST':\n            offset = 0\n        else:\n            offset = width\n        ax.plot(x[i] + offset, winner_mae, marker='*', color='gold', markersize=14, zorder=5)\n\n    ax.set_xlabel('Dish')\n    ax.set_ylabel('MAE (plates)')\n    ax.set_title('Model MAE Comparison by Dish (lower is better)')\n    ax.set_xticks(x)\n    ax.set_xticklabels(dishes, rotation=45, ha='right', fontsize=8)\n    ax.legend()\n    ax.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n    plt.tight_layout()\n    plt.show()\n\n# Show average-only dishes if any\navg_rows = results_table[results_table['Winner'] == 'AVERAGE']\nif len(avg_rows) > 0:\n    print(f\"\\nDishes using simple average (< {CFG.min_ml_days} days of data):\")\n    for _, row in avg_rows.iterrows():\n        print(f\"  - {row['Dish']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --- VISUALIZATION B: Actual vs Predicted (Last Fold, Winning Model) ---\n# Only plot dishes that went through ML (have backtest predictions)\nml_dishes = [r for r in results if r['champion'] != 'average' and r['backtest_preds'] is not None]\n\nif len(ml_dishes) > 0:\n    n_dishes = len(ml_dishes)\n    ncols = 4\n    nrows = int(np.ceil(n_dishes / ncols))\n\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 4 * nrows), squeeze=False)\n\n    for idx, r in enumerate(ml_dishes):\n        ax = axes[idx // ncols][idx % ncols]\n        dish = r['dish']\n        winner = r['champion']\n\n        preds = r['backtest_preds'].get(winner)\n        if preds is not None:\n            dates = pd.to_datetime(preds['dates'])\n            ax.plot(dates, preds['actual'], label='Actual', color='#333333', linewidth=1.5)\n            ax.plot(dates, preds['predicted'], label='Predicted', color='#E24A33',\n                    linewidth=1.5, linestyle='--')\n            ax.fill_between(dates, preds['actual'], preds['predicted'],\n                            alpha=0.15, color='#E24A33')\n\n        ax.set_title(f\"{dish}\\n({winner.upper()})\", fontsize=8, fontweight='bold')\n        ax.tick_params(axis='x', rotation=30, labelsize=6)\n        ax.tick_params(axis='y', labelsize=7)\n        if idx == 0:\n            ax.legend(fontsize=7)\n\n    for idx in range(n_dishes, nrows * ncols):\n        axes[idx // ncols][idx % ncols].set_visible(False)\n\n    fig.suptitle('Actual vs Predicted Sales (Last CV Fold, Winning Model)', fontsize=13, y=1.01)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"No ML-trained dishes to plot backtests for.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --- VISUALIZATION C: Multi-Day Forecast (14 days) ---\nforecast_date = '2026-05-20'\nrain_input = 10.0\n\nall_forecasts = {}\nday1_summary = []\n\nfor dish_name in enriched_df['dish'].unique():\n    preds = get_prediction(\n        dish=dish_name, date_str=forecast_date,\n        lat=lat_in, lon=lon_in, rain_forecast=rain_input\n    )\n    if preds and 'Error' not in preds[0]:\n        all_forecasts[dish_name] = preds\n        p0 = preds[0]\n        day1_summary.append({\n            'Dish': p0['Dish'],\n            'Day 1 Qty': p0['Prediction'],\n            'Lower': p0['Prediction_Lower'],\n            'Upper': p0['Prediction_Upper'],\n            'Model': p0['Model Used'],\n            'Trend': p0['Explanation']['Trend'],\n            'Seasonality': p0['Explanation']['Seasonality'],\n            'Holiday': p0['Explanation']['Holiday'],\n            'Weather': p0['Explanation']['Weather']\n        })\n\n# Day-1 summary table\nday1_df = pd.DataFrame(day1_summary)\nprint(f\"Forecast starting: {forecast_date} | Rain: {rain_input}mm | Horizon: {CFG.forecast_horizon} days\")\nprint(f\"{'='*90}\")\ndisplay(day1_df)\n\n# Line chart: 14-day forecast per dish with confidence bands\nn_dishes = len(all_forecasts)\nif n_dishes > 0:\n    ncols = 4\n    nrows = int(np.ceil(n_dishes / ncols))\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 4 * nrows), squeeze=False)\n\n    colors_map = {'PROPHET': '#4C72B0', 'CATBOOST': '#DD8452', 'XGBOOST': '#55A868', 'AVERAGE': '#999999'}\n\n    for idx, (dish_name, preds) in enumerate(all_forecasts.items()):\n        ax = axes[idx // ncols][idx % ncols]\n        dates = [pd.to_datetime(p['Date']) for p in preds]\n        qtys = [p['Prediction'] for p in preds]\n        lowers = [p['Prediction_Lower'] for p in preds]\n        uppers = [p['Prediction_Upper'] for p in preds]\n        model_used = preds[0]['Model Used']\n        color = colors_map.get(model_used, '#333333')\n\n        ax.plot(dates, qtys, marker='o', markersize=3, color=color, linewidth=1.5,\n                label=model_used)\n        ax.fill_between(dates, lowers, uppers, alpha=0.2, color=color)\n\n        ax.set_title(f\"{dish_name}\\n({model_used})\", fontsize=8, fontweight='bold')\n        ax.tick_params(axis='x', rotation=30, labelsize=6)\n        ax.tick_params(axis='y', labelsize=7)\n        ax.legend(fontsize=7)\n\n    for idx in range(n_dishes, nrows * ncols):\n        axes[idx // ncols][idx % ncols].set_visible(False)\n\n    fig.suptitle(f'{CFG.forecast_horizon}-Day Rolling Forecast per Dish (with Confidence Bands)',\n                 fontsize=13, y=1.01)\n    plt.tight_layout()\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}